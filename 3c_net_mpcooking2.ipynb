{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3c-net_mpcooking2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1bE6OPamvsKua2i42_lPrB54qyQYF4uGP",
      "authorship_tag": "ABX9TyMokn4Z1/Lx+B7pzzPo/L5W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VedantDesai11/3c-net_on_mpcooking2/blob/main/3c_net_mpcooking2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC_fFSvx6T8n"
      },
      "source": [
        "!git clone https://github.com/naraysa/3c-net \n",
        "!pip install tensorboard_logger"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCWXHH_R6Vom"
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "class ConvertDataset:\n",
        "     def __init__(self, reza_dataset):\n",
        "         self.feature_size = 256\n",
        "         self.num_class = reza_dataset.nDishes # number of class = number of dishes in our case\n",
        "         self.t_max = None\n",
        "         # currenttestidx\n",
        "         #testidx\n",
        "         #path_to_annotations\n",
        "         #lst_valid\n",
        "         #labels101to20\n",
        "        \n",
        "    def load_data(self):\n",
        "        \n",
        "        #returns features, labels, count_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRoRbpcF4WsN"
      },
      "source": [
        "# TESTING CELL \n",
        "\n",
        "cmd =r'/content/drive/My Drive/MPCooking 2/mpcooking2_data_pca.pickle'\n",
        "f = open(cmd, \"rb\")\n",
        "\n",
        "reza_dataset = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLoWYDEN5Fj4",
        "outputId": "c852655b-34af-4ed6-fe7a-de0c2bf4e15b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#print reza_dataset.train[0][0] # video name\n",
        "print reza_dataset.train[0][1].shape # action label per frame\n",
        "#print reza_dataset.train[0][2] # actions order label\n",
        "print reza_dataset.train[0][3].shape # rgb features\n",
        "print reza_dataset.train[0][4].shape # flow features"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(910,)\n",
            "(128, 910)\n",
            "(128, 910)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afpbEs6M6kPu"
      },
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import os\n",
        "import torch\n",
        "from model import Model\n",
        "from video_dataset import Dataset\n",
        "from test import test\n",
        "from train import train\n",
        "from tensorboard_logger import Logger\n",
        "import options\n",
        "from center_loss import CenterLoss\n",
        "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "import torch.optim as optim\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    args = options.parser.parse_args(['--dataset-name', 'Thumos14'])\n",
        "    torch.manual_seed(args.seed)\n",
        "    torch.cuda.manual_seed_all(args.seed)\n",
        "    device = torch.device(\"cuda\")\n",
        "    \n",
        "    t_max = 750\n",
        "    t_max_ctc = 2800\n",
        "    if args.activity_net:\n",
        "        t_max = 200\n",
        "        t_max_ctc = 400\n",
        "\n",
        "\n",
        "    #dataset = Dataset(args)\n",
        "    reza_dataset = pickle.load(open('/content/drive/My Drive/MPCooking 2/mpcooking2_data_pca.pickle', \"rb\"))\n",
        "    \n",
        "    dataset = ConvertDataset(reza_dataset)\n",
        "\n",
        "    \n",
        "    os.system('mkdir -p ./ckpt/')\n",
        "    os.system('mkdir -p ./logs/' + args.model_name)\n",
        "    logger = Logger('./logs/' + args.model_name)\n",
        "    \n",
        "    model = Model(dataset.feature_size, dataset.num_class, dataset.labels101to20).to(device)\n",
        "\n",
        "    if args.eval_only and args.pretrained_ckpt is None:\n",
        "        print('***************************')\n",
        "        print('Pretrained Model NOT Loaded')\n",
        "        print('Evaluating on Random Model')\n",
        "        print('***************************')\n",
        "\n",
        "    if args.pretrained_ckpt is not None:\n",
        "        model.load_state_dict(torch.load(args.pretrained_ckpt))\n",
        "\n",
        "    best_acc = 0\n",
        "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=0.0005)  \n",
        "    #criterion_cent_f = CenterLoss(num_classes=dataset.num_class, feat_dim=1024, use_gpu=True)\n",
        "    criterion_cent_f = CenterLoss(num_classes=dataset.num_class, feat_dim=128, use_gpu=True)\n",
        "    optimizer_centloss_f = torch.optim.SGD(criterion_cent_f.parameters(), lr=0.1)\n",
        "    #criterion_cent_r = CenterLoss(num_classes=dataset.num_class, feat_dim=1024, use_gpu=True)\n",
        "    criterion_cent_r = CenterLoss(num_classes=dataset.num_class, feat_dim=128, use_gpu=True)\n",
        "    optimizer_centloss_r = torch.optim.SGD(criterion_cent_r.parameters(), lr=0.1)\n",
        "\n",
        "    criterion_cent_all=[criterion_cent_f, criterion_cent_r]\n",
        "    optimizer_centloss_all=[optimizer_centloss_f, optimizer_centloss_r]\n",
        "\n",
        "    for itr in range(args.max_iter):\n",
        "        dataset.t_max = t_max\n",
        "        if itr % 2 == 0 and itr > 000:\n",
        "            dataset.t_max = t_max_ctc\n",
        "        if not args.eval_only:\n",
        "            train(itr, dataset, args, model, optimizer, criterion_cent_all, optimizer_centloss_all, logger, device)\n",
        "          \n",
        "        if itr % 500 == 0 and (not itr == 0 or args.eval_only):\n",
        "            acc = test(itr, dataset, args, model, logger, device)\n",
        "            print(args.summary)\n",
        "            if acc > best_acc and not args.eval_only:\n",
        "              torch.save(model.state_dict(), './ckpt/' + args.model_name + '.pkl')\n",
        "              best_acc = acc\n",
        "        if args.eval_only:\n",
        "            print('Done Eval!')\n",
        "            break\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}